{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T03:41:19.425869Z",
     "iopub.status.busy": "2025-11-10T03:41:19.425703Z",
     "iopub.status.idle": "2025-11-10T03:41:31.459750Z",
     "shell.execute_reply": "2025-11-10T03:41:31.459038Z",
     "shell.execute_reply.started": "2025-11-10T03:41:19.425853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install numpy==1.24.3 opencv-python==4.8.0.76 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# File to delete\n",
    "file_path = \"/kaggle/working/yolo11n.pt\"\n",
    "\n",
    "# Check if it exists and remove it\n",
    "if os.path.exists(file_path) and os.path.isfile(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"Deleted file: {file_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T03:42:07.286715Z",
     "iopub.status.busy": "2025-11-10T03:42:07.286036Z",
     "iopub.status.idle": "2025-11-10T03:43:33.494215Z",
     "shell.execute_reply": "2025-11-10T03:43:33.493503Z",
     "shell.execute_reply.started": "2025-11-10T03:42:07.286677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Source folder (your uploaded dataset)\n",
    "src_folder = \"/kaggle/input/yolo-dataset/All-weapons-data-1\"\n",
    "\n",
    "# Destination folder in working directory\n",
    "dst_folder = \"/kaggle/working/All-weapons-data-1\"\n",
    "\n",
    "# Copy entire folder and overwrite if it exists\n",
    "shutil.copytree(src_folder, dst_folder, dirs_exist_ok=True)\n",
    "\n",
    "print(f\"Dataset copied to: {dst_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T03:43:58.235075Z",
     "iopub.status.busy": "2025-11-10T03:43:58.234504Z",
     "iopub.status.idle": "2025-11-10T03:43:58.261416Z",
     "shell.execute_reply": "2025-11-10T03:43:58.260818Z",
     "shell.execute_reply.started": "2025-11-10T03:43:58.235051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_path = \"/kaggle/working/All-weapons-data-1/data.yaml\"\n",
    "\n",
    "# Load YAML\n",
    "with open(yaml_path, 'r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "# Update paths to point to 'images' folders\n",
    "data['train'] = \"/kaggle/working/All-weapons-data-1/train/images\"\n",
    "data['val']   = \"/kaggle/working/All-weapons-data-1/valid/images\"\n",
    "data['test']  = \"/kaggle/working/All-weapons-data-1/test/images\"\n",
    "\n",
    "# Save updated YAML\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.safe_dump(data, f)\n",
    "\n",
    "print(\"Updated data.yaml paths to point directly to images folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T03:44:01.880746Z",
     "iopub.status.busy": "2025-11-10T03:44:01.880476Z",
     "iopub.status.idle": "2025-11-10T03:45:20.271968Z",
     "shell.execute_reply": "2025-11-10T03:45:20.271298Z",
     "shell.execute_reply.started": "2025-11-10T03:44:01.880724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T03:45:29.138120Z",
     "iopub.status.busy": "2025-11-10T03:45:29.137693Z",
     "iopub.status.idle": "2025-11-10T03:45:29.362431Z",
     "shell.execute_reply": "2025-11-10T03:45:29.361366Z",
     "shell.execute_reply.started": "2025-11-10T03:45:29.138089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Shell command to copy the file to the writable working directory\n",
    "!cp /kaggle/input/weapon-model/pytorch/default/1/last.pt /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14698,
     "status": "ok",
     "timestamp": 1762630480494,
     "user": {
      "displayName": "Hashir Ali",
      "userId": "05267088391613122548"
     },
     "user_tz": -300
    },
    "id": "8XEWS2TrtfFC",
    "outputId": "1e4a400a-8381-47fe-e45d-1fdf81347e61",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6986,
     "status": "error",
     "timestamp": 1762630687354,
     "user": {
      "displayName": "Hashir Ali",
      "userId": "05267088391613122548"
     },
     "user_tz": -300
    },
    "id": "7Pwpi0aSDGg2",
    "outputId": "faebad03-b477-455a-ad0a-f8680917594b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"iqWudABIjfXqATDPAmLo\")\n",
    "# project = rf.workspace(\"custome-yolo\").project(\"all-weapons-data-jqimy\")\n",
    "# version = project.version(1)\n",
    "# dataset = version.download(\"yolov8\",location=\"C:/Users/PMLS/Downloads\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGXwWm9TWQ9p"
   },
   "source": [
    "We will first check if all the train , test and valid set have correct corresponding images and labels or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ1WLMftriTT"
   },
   "source": [
    "We dont have to worry about dimensions , yolo will take care of it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from collections import Counter\n",
    "\n",
    "# label_dir = \"D:/ML/Tasks/CNN/All-weapons-data-1/train/labels\"  # adjust path if needed\n",
    "# all_labels = []\n",
    "\n",
    "# for file in os.listdir(label_dir):\n",
    "#     if file.endswith(\".txt\"):\n",
    "#         with open(os.path.join(label_dir, file)) as f:\n",
    "#             for line in f:\n",
    "#                 class_id = int(line.split()[0])\n",
    "#                 all_labels.append(class_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(Counter(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1762630485063,
     "user": {
      "displayName": "Hashir Ali",
      "userId": "05267088391613122548"
     },
     "user_tz": -300
    },
    "id": "XKCJz3K3vRgi",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1762630499582,
     "user": {
      "displayName": "Hashir Ali",
      "userId": "05267088391613122548"
     },
     "user_tz": -300
    },
    "id": "yaMXDvSfvYh0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO(\"yolov8n.yaml\")  # just the architecture, no weights\n",
    "model.train(\n",
    "    data=\"/kaggle/working/All-weapons-data-1/data.yaml\",\n",
    "    project=\"/kaggle/working\",\n",
    "    name=\"weapon_model\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    amp=False,\n",
    "    optimizer=\"SGD\",\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    workers=0,\n",
    "    augment=True,\n",
    "    mosaic=True,\n",
    "    mixup=True,\n",
    "    flipud=0.5,\n",
    "    fliplr=0.5,\n",
    "    degrees=15,\n",
    "    translate=0.1,\n",
    "    scale=0.1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T03:45:46.770814Z",
     "iopub.status.busy": "2025-11-10T03:45:46.770530Z",
     "iopub.status.idle": "2025-11-10T07:36:54.124781Z",
     "shell.execute_reply": "2025-11-10T07:36:54.124108Z",
     "shell.execute_reply.started": "2025-11-10T03:45:46.770783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Configuration\n",
    "CHECKPOINT_PATH = \"/kaggle/working/last.pt\"\n",
    "DATA_YAML = \"/kaggle/working/All-weapons-data-1/data.yaml\"\n",
    "PROJECT_DIR = \"/kaggle/working\"\n",
    "MODEL_NAME = \"weapon_model_resume\"\n",
    "TOTAL_EPOCHS = 100  # Total epochs you want to train\n",
    "EPOCHS_PER_ITERATION = 10  # Train 10 epochs at a time\n",
    "\n",
    "# Calculate number of iterations needed\n",
    "num_iterations = TOTAL_EPOCHS // EPOCHS_PER_ITERATION\n",
    "\n",
    "print(f\"Starting training loop: {num_iterations} iterations of {EPOCHS_PER_ITERATION} epochs each\")\n",
    "print(f\"Total target epochs: {TOTAL_EPOCHS}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ITERATION {iteration + 1}/{num_iterations}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Load the model from checkpoint\n",
    "        if os.path.exists(CHECKPOINT_PATH):\n",
    "            print(f\"Loading checkpoint from: {CHECKPOINT_PATH}\")\n",
    "            model = YOLO(CHECKPOINT_PATH)\n",
    "        else:\n",
    "            print(f\"Checkpoint not found at {CHECKPOINT_PATH}\")\n",
    "            print(\"Starting fresh training (this should only happen on first run)\")\n",
    "            model = YOLO(\"yolov8n.yaml\")  # Replace with your base model if different\n",
    "        \n",
    "        # Train for EPOCHS_PER_ITERATION epochs\n",
    "        print(f\"\\nStarting training for {EPOCHS_PER_ITERATION} epochs...\")\n",
    "        results = model.train(\n",
    "            data=DATA_YAML,\n",
    "            project=PROJECT_DIR,\n",
    "            name=MODEL_NAME,\n",
    "            epochs=EPOCHS_PER_ITERATION,\n",
    "            resume=False,  # Set to False since we're managing epochs manually\n",
    "            imgsz=640,\n",
    "            batch=16,\n",
    "            lr0=0.001,\n",
    "            lrf=0.01,\n",
    "            amp=False,\n",
    "            optimizer=\"SGD\",\n",
    "            momentum=0.937,\n",
    "            weight_decay=0.0005,\n",
    "            workers=0,\n",
    "            augment=True,\n",
    "            mosaic=True,\n",
    "            mixup=True,\n",
    "            flipud=0.5,\n",
    "            fliplr=0.5,\n",
    "            degrees=15,\n",
    "            translate=0.1,\n",
    "            scale=0.1\n",
    "        )\n",
    "        \n",
    "        # Find the newly trained model (last.pt from the run directory)\n",
    "        run_dir = Path(PROJECT_DIR) / MODEL_NAME\n",
    "        new_checkpoint = run_dir / \"weights\" / \"last.pt\"\n",
    "        \n",
    "        if new_checkpoint.exists():\n",
    "            print(f\"\\nTraining iteration completed!\")\n",
    "            print(f\"Copying checkpoint from: {new_checkpoint}\")\n",
    "            print(f\"                     to: {CHECKPOINT_PATH}\")\n",
    "            \n",
    "            # Copy the new checkpoint to our main checkpoint location\n",
    "            shutil.copy2(new_checkpoint, CHECKPOINT_PATH)\n",
    "            print(\"Checkpoint updated successfully!\")\n",
    "            \n",
    "            # Optional: Download the checkpoint (Kaggle specific)\n",
    "            # This creates a copy in the output directory which Kaggle can download\n",
    "            try:\n",
    "                output_checkpoint = f\"/kaggle/working/checkpoint_iter_{iteration + 1}.pt\"\n",
    "                shutil.copy2(CHECKPOINT_PATH, output_checkpoint)\n",
    "                print(f\"Checkpoint copied to output: {output_checkpoint}\")\n",
    "                print(\"  (This file will be available for download after session ends)\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not create downloadable copy: {e}\")\n",
    "            \n",
    "            # Also copy best.pt if available\n",
    "            best_checkpoint = run_dir / \"weights\" / \"best.pt\"\n",
    "            if best_checkpoint.exists():\n",
    "                best_output = f\"/kaggle/working/best_iter_{iteration + 1}.pt\"\n",
    "                shutil.copy2(best_checkpoint, best_output)\n",
    "                print(f\"Best model copied to: {best_output}\")\n",
    "        else:\n",
    "            print(f\"Warning: Could not find checkpoint at {new_checkpoint}\")\n",
    "            print(\"Training may have failed or checkpoint location changed.\")\n",
    "        \n",
    "        print(f\"\\nCompleted iteration {iteration + 1}/{num_iterations}\")\n",
    "        print(f\"Total epochs trained so far: {(iteration + 1) * EPOCHS_PER_ITERATION}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error during iteration {iteration + 1}: {str(e)}\")\n",
    "        print(\"Attempting to continue with next iteration...\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING LOOP COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final checkpoint available at: {CHECKPOINT_PATH}\")\n",
    "print(\"\\nAll iteration checkpoints are saved in /kaggle/working/ for download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoC3VqTaGaOLceKILpAXRi",
   "mount_file_id": "1ZgNiA0PmstqimtoFF7TuRDCO6uMcyy37",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8689004,
     "sourceId": 13666128,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 495248,
     "modelInstanceId": 479489,
     "sourceId": 635909,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
